{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import requests\n",
    "import logging\n",
    "base_url = \"https://arxiv.paperswithcode.com/api/v0/papers/\"\n",
    "github_url = \"https://api.github.com/search/repositories\"\n",
    "arxiv_url = \"http://arxiv.org/\"\n",
    "\n",
    "def get_daily_papers(topic, query=\"agent\", max_results=2):\n",
    "    \"\"\"\n",
    "    @param topic: str\n",
    "    @param query: str\n",
    "    @return paper_with_code: dict\n",
    "    \"\"\"\n",
    "    # output\n",
    "    content = dict()\n",
    "    content_to_web = dict()\n",
    "    print(\"-----------------\")\n",
    "    print(f\"query is {query}\")\n",
    "    print(\"-----------------\")\n",
    "    search_engine = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=max_results,\n",
    "        sort_by=arxiv.SortCriterion.SubmittedDate\n",
    "    )\n",
    "\n",
    "    for result in search_engine.results():\n",
    "\n",
    "        paper_id = result.get_short_id()\n",
    "        paper_title = result.title\n",
    "        paper_url = result.entry_id\n",
    "        code_url = base_url + paper_id  # TODO\n",
    "\n",
    "        paper_abstract = result.summary.replace(\"\\n\", \" \")\n",
    "\n",
    "        paper_abstract = paper_abstract.replace(\"|\", \",\")\n",
    "        paper_abstract = paper_abstract.replace(\"\\n\", \" \")\n",
    "\n",
    "\n",
    "        primary_category = result.primary_category\n",
    "        publish_time = result.published.date()\n",
    "        update_time = result.updated.date()\n",
    "        comments = result.comment\n",
    "\n",
    "        # eg: 2108.09112v1 -> 2108.09112\n",
    "        ver_pos = paper_id.find('v')\n",
    "        if ver_pos == -1:\n",
    "            paper_key = paper_id\n",
    "        else:\n",
    "            paper_key = paper_id[0:ver_pos]\n",
    "        paper_url = arxiv_url + 'abs/' + paper_key\n",
    "\n",
    "        try:\n",
    "            # source code link\n",
    "            r = requests.get(code_url).json()\n",
    "            repo_url = None\n",
    "            if \"official\" in r and r[\"official\"]:\n",
    "                repo_url = r[\"official\"][\"url\"]\n",
    "\n",
    "            if repo_url is not None:\n",
    "                content[paper_key] = \"|**{}**|**{}**|[{}]({})|**[link]({})**|**{}**|\\n\".format(\n",
    "                    update_time, [paper_title](paper_url), paper_key, paper_url, repo_url, paper_abstract)\n",
    "                content_to_web[paper_key] = \"- {}, **{}**, Paper: [{}]({}), Code: **[{}]({})**\".format(\n",
    "                    update_time, [paper_title](paper_url), paper_url, paper_url, repo_url, repo_url)\n",
    "\n",
    "            else:\n",
    "                content[paper_key] = \"|**{}**|**{}**|[{}]({})|null|{}|\\n\".format(\n",
    "                    update_time, [paper_title](paper_url), paper_key, paper_url, paper_abstract)\n",
    "                content_to_web[paper_key] = \"- {}, **{}**, Paper: [{}]({}),{}\".format(\n",
    "                    update_time, [paper_title](paper_url), paper_url, paper_url, paper_abstract)\n",
    "\n",
    "            # TODO: select useful comments\n",
    "            comments = None\n",
    "            if comments != None:\n",
    "                content_to_web[paper_key] += f\", {comments}\\n\"\n",
    "            else:\n",
    "                content_to_web[paper_key] += f\"\\n\"\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"exception: {e} with id: {paper_key}\")\n",
    "\n",
    "    data = {topic: content}\n",
    "    data_web = {topic: content_to_web}\n",
    "    return data, data_web\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_63512\\441346572.py:17: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for result in search_engine.results():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technical Report v1 (44 pages, 23 figures, project page:\n",
      "  https://sgp-bench.github.io/)\n",
      "None\n",
      "32 pages\n",
      "Pre-print. 11 pages main, 8 pages app., 28 figures\n",
      "None\n",
      "None\n",
      "None\n",
      "This paper is an extension of our ICCV 23 paper (arXiv:2303.05118)\n",
      "None\n",
      "16 pages, 8 figures, 2 tables\n",
      "None\n",
      "None\n",
      "33 pages, 14 figures\n",
      "None\n",
      "None\n",
      "10 pages, 6 figures, 5 tables\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "for companion code, see https://github.com/bob-carpenter/adaptive-hmc\n",
      "Accepted for ECCV 2024\n",
      "34 pages. arXiv admin note: text overlap with arXiv:2402.19271\n",
      "None\n",
      "None\n",
      "20 pages, 10 figures, 2 tables, submitted to PRC\n",
      "13 pages, 11 figures\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "249 plots in 48 figures, and 81 tables. This is an extended version\n",
      "  of the paper Linares L\\'opez, Carlos and Herman, Ian. 2024. Evolving A* to\n",
      "  Efficiently Solve the k Shortest-Path Problem. Proceedings of the European\n",
      "  Conference on Artificial Intelligence (ECAI). To appear\n",
      "Preprint accepted for 15th International Conference on Computational\n",
      "  Logistics\n",
      "Accepted by ECML PKDD 2024\n",
      "None\n",
      "None\n",
      "10 pages, 6 Figures, 1 Table\n",
      "6 pages, 5 figures\n",
      "None\n",
      "This work is under-review\n",
      "6 pages, 5 figures, IEEE MMSP 2024\n",
      "None\n",
      "None\n",
      "Web: https://water-splatting.github.io\n",
      "Accepted by ACM Transactions on Multimedia Computing, Communications,\n",
      "  and Applications\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "Submitted to the proceedings of the 28th International Conference on\n",
      "  Domain Decomposition Methods (DDM28)\n",
      "33 pages, 8 figures\n",
      "GenLaw ICML 2024\n",
      "None\n",
      "None\n",
      "63 pages, 6 figures\n",
      "None\n",
      "None\n",
      "6 pages, 4 figures\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "Accepted by ICANN 2024\n",
      "8 pages, 5 figures, 2 tables\n",
      "8 pages, 4 figures, accepted by ECAI\n",
      "None\n",
      "10 pages, 3 figures\n",
      "Accepted by ACM MM 2024\n",
      "None\n",
      "11 pages, 11 figures. Manuscript submitted to IEEE Transactions on\n",
      "  Wireless Communications. arXiv admin note: substantial text overlap with\n",
      "  arXiv:2406.19078, arXiv:2402.05583\n",
      "Accepted by TPAMI-2024\n",
      "17 pages, 10 figures\n",
      "20 pages\n",
      "None\n",
      "None\n",
      "prepared as a contribution to the special issue of \"Journal of\n",
      "  Physics A: Mathematical and Theoretical\" dedicated to the memory of Stanley\n",
      "  Deser; 20 pages, no figures\n",
      "None\n",
      "None\n",
      "13 pages, 4 figures, 6 tables\n",
      "None\n",
      "Code is available at https://github.com/AlexYangxx/ColorMamba\n",
      "Accepted at AI for 3D Generation, CVPR Workshop\n",
      "None\n",
      "58 pages, 16 figures. Comments welcome!\n",
      "In Peer Review\n",
      "36 pages, 6 figures,\n",
      "16 pages, CDC 2024\n",
      "None\n",
      "None\n",
      "None\n",
      "19 pages, 5 figures\n",
      "10 pages, 7 figures\n",
      "Under Review\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "import requests\n",
    "import logging\n",
    "base_url = \"https://arxiv.paperswithcode.com/api/v0/papers/\"\n",
    "github_url = \"https://api.github.com/search/repositories\"\n",
    "arxiv_url = \"http://arxiv.org/\"\n",
    "query = \"computational argumentation\"\n",
    "max_results = 100\n",
    " \n",
    "\n",
    "search_engine = arxiv.Search(\n",
    "    query=query,\n",
    "    max_results=max_results,\n",
    "    sort_by=arxiv.SortCriterion.SubmittedDate\n",
    ")\n",
    "\n",
    "for result in search_engine.results():\n",
    "\n",
    "    paper_id = result.get_short_id()\n",
    "    paper_title = result.title\n",
    "    paper_comment = result.comment\n",
    "    print(paper_comment)\n",
    "    paper_url = result.entry_id\n",
    "    code_url = base_url + paper_id  # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 'Accepted by ICANN 2024', found: 'ICANN 2024'\n",
      "In '8 pages, 4 figures, accepted by ECAI', found: 'ECAI'\n",
      "In '10 pages, 3 figures', no match found.\n",
      "In 'accepted by ACM MM 2024', found: 'ACM MM 2024'\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 定义正则表达式\n",
    "pattern = r\"(?i)(?<=accepted by\\s).*\"\n",
    "\n",
    "# 定义一些示例文本\n",
    "texts = [\n",
    "    \"Accepted by ICANN 2024\",\n",
    "    \"8 pages, 4 figures, accepted by ECAI\",\n",
    "    \"10 pages, 3 figures\",\n",
    "    \"accepted by ACM MM 2024\"\n",
    "]\n",
    "\n",
    "# 遍历所有文本，使用正则表达式匹配\n",
    "for text in texts:\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        print(f\"In '{text}', found: '{match.group()}'\")\n",
    "    else:\n",
    "        print(f\"In '{text}', no match found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACM MM 2024\n"
     ]
    }
   ],
   "source": [
    "print(match.group())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swanlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f506cfc2517e47c35404def47551dfa88d4f132114f0c659b9a5b86b0769461"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
